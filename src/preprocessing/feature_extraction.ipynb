{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = \"D:/Projects/Summer-2024-ECE-597-Group8\"\n",
    "normal_sample_numbers = 2571 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_extract_subject_body(text):\n",
    "    # Extract the subject using a regular expression\n",
    "    subject_match = re.search(r\"Subject: (.*)\", text)\n",
    "    subject = subject_match.group(1) if subject_match else \"Subject Not Found\"\n",
    "\n",
    "    # Clean the text by removing everything from \"Message-ID:\" up to \"X-FileName:\"\n",
    "    cleaned_text = re.sub(r\"Message-ID:.*?X-FileName:.*?\\n\", \"\", text, flags=re.S)\n",
    "\n",
    "    return subject, cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phishing_data_path = os.path.join(\n",
    "    project_root, \"data\", \"raw\", \"CaptstoneProjectData_2024.csv\"\n",
    ")\n",
    "normal_data_path = os.path.join(\n",
    "    project_root, \"data\", \"raw\", \"EnronEmailDataset.csv\"\n",
    ")\n",
    "\n",
    "phishing_data = pd.read_csv(phishing_data_path)\n",
    "normal_data = pd.read_csv(\n",
    "    normal_data_path, nrows=normal_sample_numbers\n",
    ")\n",
    "\n",
    "phishing_data.drop(columns=[\"Unnamed: 2\", \"Unnamed: 3\"], inplace=True)\n",
    "phishing_data[\"Subject\"] = phishing_data[\"Subject\"].fillna(\"Subject Not Found\")\n",
    "phishing_data.dropna(\n",
    "    subset=[\"Body\"], inplace=True\n",
    ")\n",
    "phishing_data.reset_index(drop=True, inplace=True)\n",
    "normal_data[[\"Subject\", \"Body\"]] = normal_data[\"message\"].apply(\n",
    "    lambda x: pd.Series(normal_extract_subject_body(x))\n",
    ")\n",
    "\n",
    "phishing_data[\"Label\"] = 1\n",
    "normal_data[\"Label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28281 entries, 0 to 28280\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Subject  28281 non-null  object\n",
      " 1   Body     28281 non-null  object\n",
      " 2   Label    28281 non-null  int64 \n",
      " 3   file     25710 non-null  object\n",
      " 4   message  25710 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.1+ MB\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 28281 entries, 0 to 28280\n",
      "Series name: Label\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "28281 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 221.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_data = pd.concat([phishing_data, normal_data], ignore_index=True)\n",
    "df_data.info()\n",
    "df_labels = df_data[\"Label\"]\n",
    "df_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Subject  \\\n",
      "0      ®Review your shipment details / Shipment Notif...   \n",
      "1                                Υоur ассоunt іѕ оn hоld   \n",
      "2      Completed: Invoice # KZ89TYS2564  +1.813.776.1410   \n",
      "3                                 UVic IMPORTANT NOTICE!   \n",
      "4              You have (6) Suspended incoming messages    \n",
      "...                                                  ...   \n",
      "28276    Out of the Office - Afternoon of Friday, June 9   \n",
      "28277                                    Re: TDS project   \n",
      "28278                              Global Systems Matrix   \n",
      "28279             Mid Year Energy Operations PRC Meeting   \n",
      "28280                             Mgmt Summary & HotList   \n",
      "\n",
      "                                                    Body  Label  \\\n",
      "0       [] Dear , An agent of ours tried to ship a pa...      1   \n",
      "1       Votre réponse a bien été prise en compte. [] ...      1   \n",
      "2               [DocuSign] [] Your document has been ...      1   \n",
      "3      Your UVIC account has been filed under the lis...      1   \n",
      "4       Message generated from   source. Sender      ...      1   \n",
      "...                                                  ...    ...   \n",
      "28276   I will be out of the office after noon on Fri...      0   \n",
      "28277   You might hear of this, so I thought I better...      0   \n",
      "28278   Rick - You had asked a while back for a matri...      0   \n",
      "28279   Our mid year PRC meeting will be held Monday,...      0   \n",
      "28280   Attached are the Mgmt Summary, Hot List and M...      0   \n",
      "\n",
      "                                  file  \\\n",
      "0                                  NaN   \n",
      "1                                  NaN   \n",
      "2                                  NaN   \n",
      "3                                  NaN   \n",
      "4                                  NaN   \n",
      "...                                ...   \n",
      "28276  beck-s/discussion_threads/1158.   \n",
      "28277  beck-s/discussion_threads/1159.   \n",
      "28278  beck-s/discussion_threads/1160.   \n",
      "28279  beck-s/discussion_threads/1161.   \n",
      "28280  beck-s/discussion_threads/1162.   \n",
      "\n",
      "                                                 message  \\\n",
      "0                                                    NaN   \n",
      "1                                                    NaN   \n",
      "2                                                    NaN   \n",
      "3                                                    NaN   \n",
      "4                                                    NaN   \n",
      "...                                                  ...   \n",
      "28276  Message-ID: <8477157.1075855835539.JavaMail.ev...   \n",
      "28277  Message-ID: <3475775.1075855835565.JavaMail.ev...   \n",
      "28278  Message-ID: <32640873.1075855835587.JavaMail.e...   \n",
      "28279  Message-ID: <13745048.1075855835616.JavaMail.e...   \n",
      "28280  Message-ID: <24326924.1075855835645.JavaMail.e...   \n",
      "\n",
      "                                               Full_Text  Word_Count  \n",
      "0      ®Review your shipment details / Shipment Notif...         119  \n",
      "1      Υоur ассоunt іѕ оn hоld Votre réponse a bien é...         119  \n",
      "2      Completed: Invoice # KZ89TYS2564  +1.813.776.1...         261  \n",
      "3      UVic IMPORTANT NOTICE!Your UVIC account has be...          83  \n",
      "4      You have (6) Suspended incoming messages  Mess...         169  \n",
      "...                                                  ...         ...  \n",
      "28276  Out of the Office - Afternoon of Friday, June ...          62  \n",
      "28277  Re: TDS project You might hear of this, so I t...        1728  \n",
      "28278  Global Systems Matrix Rick - You had asked a w...          61  \n",
      "28279  Mid Year Energy Operations PRC Meeting Our mid...         206  \n",
      "28280  Mgmt Summary & HotList Attached are the Mgmt S...          18  \n",
      "\n",
      "[28281 rows x 7 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28281 entries, 0 to 28280\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Word_Count  28281 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 221.1 KB\n"
     ]
    }
   ],
   "source": [
    "from get_email_length import fetch_email_length\n",
    "\n",
    "df_wordCount = fetch_email_length(df_data.copy())\n",
    "df_wordCount.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28281 entries, 0 to 28280\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Homoglyphs  28281 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 221.1 KB\n"
     ]
    }
   ],
   "source": [
    "from homoglyphs import feature_homoglyphs\n",
    "\n",
    "df_homoglyphs = feature_homoglyphs(df_data.copy())\n",
    "df_homoglyphs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28281 entries, 0 to 28280\n",
      "Data columns (total 1 columns):\n",
      " #   Column                Non-Null Count  Dtype\n",
      "---  ------                --------------  -----\n",
      " 0   Total_Abnormal_Count  28281 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 221.1 KB\n"
     ]
    }
   ],
   "source": [
    "from abnormal_number_extract import extract_abnormal_number\n",
    "\n",
    "df_abnormal = extract_abnormal_number(df_data.copy())\n",
    "df_abnormal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28281 entries, 0 to 28280\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   html_tags  28281 non-null  int64\n",
      " 1   js_code    28281 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 442.0 KB\n"
     ]
    }
   ],
   "source": [
    "from html_JS import extract_features_from_message\n",
    "\n",
    "df_specials = df_data.copy().apply(\n",
    "    lambda row: extract_features_from_message(\n",
    "        str(row['Subject']) + ' ' + str(row['Body'])\n",
    "    ), axis=1\n",
    ")\n",
    "df_specials = pd.DataFrame(df_specials.tolist(), columns=['html_tags', 'js_code'])\n",
    "df_specials.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28281 entries, 0 to 28280\n",
      "Columns: 187 entries, bow_able to bow_year\n",
      "dtypes: int64(187)\n",
      "memory usage: 40.3 MB\n"
     ]
    }
   ],
   "source": [
    "from phishing_bow import feature_extract_bow\n",
    "\n",
    "df_bow = feature_extract_bow(df_data.copy())\n",
    "df_bow.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\xfy53\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28281 entries, 0 to 28280\n",
      "Columns: 187 entries, tfidf_able to tfidf_year\n",
      "dtypes: float64(187)\n",
      "memory usage: 40.3 MB\n"
     ]
    }
   ],
   "source": [
    "from phishing_tfidf import feature_extract_tfidf\n",
    "\n",
    "df_tfidf = feature_extract_tfidf(df_data.copy())\n",
    "df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.concat([df_wordCount, df_homoglyphs, df_abnormal, df_specials], axis=1)\n",
    "\n",
    "df_features_labels = pd.concat([df_features, df_labels], axis=1)\n",
    "df_bow_labels = pd.concat([df_bow, df_labels], axis=1)\n",
    "df_tfidf_labels = pd.concat([df_tfidf, df_labels], axis=1)\n",
    "df_features_bow_labels = pd.concat([df_features, df_bow, df_labels], axis=1)\n",
    "df_features_tfidf_labels = pd.concat([df_features, df_tfidf, df_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_labels = df_features_labels.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_bow_labels = df_bow_labels.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_tfidf_labels = df_tfidf_labels.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_features_bow_labels = df_features_bow_labels.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_features_tfidf_labels = df_features_tfidf_labels.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "df_features_labels.to_csv(os.path.join(project_root, \"data\", \"processed\", \"features_labels.csv\"), index=False)\n",
    "df_bow_labels.to_csv(os.path.join(project_root, \"data\", \"processed\", \"bow_labels.csv\"), index=False)\n",
    "df_tfidf_labels.to_csv(os.path.join(project_root, \"data\", \"processed\", \"tfidf_labels.csv\"), index=False)\n",
    "df_features_bow_labels.to_csv(os.path.join(project_root, \"data\", \"processed\", \"features_bow_labels.csv\"), index=False)\n",
    "df_features_tfidf_labels.to_csv(os.path.join(project_root, \"data\", \"processed\", \"features_tfidf_labels.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
