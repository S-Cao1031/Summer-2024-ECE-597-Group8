{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_predict,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    KFold,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, RobustScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = \"/Users/feiyixie/Projects/Summer-2024-ECE-597-Group8\"\n",
    "data_path = os.path.join(project_root, \"data\", \"processed\", \"features_bow_labels.csv\")\n",
    "model_path = os.path.join(project_root, 'data', 'models', 'best_cnn_model_bow.keras')\n",
    "random_state = 42\n",
    "test_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df = df.drop(columns=[\"js_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(x):\n",
    "    return np.log1p(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_log_transform_StandardScaler = Pipeline(\n",
    "    steps=[\n",
    "        (\"log_transform\", FunctionTransformer(log_transform)),\n",
    "        (\"StandardScaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline_log_transform_RobustScaler = Pipeline(\n",
    "    steps=[\n",
    "        (\"log_transform\", FunctionTransformer(log_transform)),\n",
    "        (\"RobustScaler\", RobustScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "features_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"features_processer\",\n",
    "            pipeline_log_transform_RobustScaler,\n",
    "            [\n",
    "                \"Word_Count\",\n",
    "                \"Homoglyphs\",\n",
    "                \"Total_Abnormal_Count\",\n",
    "                \"html_tags\",\n",
    "            ],\n",
    "        ),\n",
    "        (\n",
    "            \"bow_processer\",\n",
    "            pipeline_log_transform_StandardScaler,\n",
    "            [col for col in df.columns if col.startswith('BoW_')]\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_preprocessor.fit_transform(df.drop(columns=[\"Label\"]))\n",
    "y = df[\"Label\"].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Reshape the data for CNN\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Define a custom F1-score metric\n",
    "def f1_score_metric(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.round(K.cast(y_pred, 'float32'))\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float32'), axis=0)\n",
    "    tn = K.sum(K.cast((1 - y_true) * (1 - y_pred), 'float32'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "    \n",
    "    f1 = 2 * p * r / (p + r + K.epsilon())\n",
    "    f1 = K.mean(f1)\n",
    "    return f1\n",
    "\n",
    "# Define the model creation function\n",
    "def create_model(trial):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train_reshaped.shape[1], 1)))\n",
    "    model.add(Conv1D(filters=trial.suggest_int('filters', 16, 128), \n",
    "                     kernel_size=trial.suggest_int('kernel_size', 2, 5), \n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=trial.suggest_int('pool_size', 2, 4)))\n",
    "    model.add(Conv1D(filters=trial.suggest_int('filters2', 16, 128), \n",
    "                     kernel_size=trial.suggest_int('kernel_size2', 2, 5), \n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=trial.suggest_int('pool_size2', 2, 4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=trial.suggest_int('units', 32, 256), activation='relu'))\n",
    "    model.add(Dropout(rate=trial.suggest_float('dropout_rate', 0.2, 0.5)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=trial.suggest_categorical('optimizer', ['adam', 'rmsprop']),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[f1_score_metric])\n",
    "    return model\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, valid_index in skf.split(X_train_reshaped, y_train):\n",
    "        X_t, X_v = X_train_reshaped[train_index], X_train_reshaped[valid_index]\n",
    "        y_t, y_v = y_train[train_index], y_train[valid_index]\n",
    "\n",
    "        model = create_model(trial)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        model.fit(X_t, y_t, \n",
    "                  epochs=trial.suggest_int('epochs', 10, 50), \n",
    "                  batch_size=trial.suggest_int('batch_size', 32, 256),\n",
    "                  validation_data=(X_v, y_v), \n",
    "                  callbacks=[early_stopping], \n",
    "                  verbose=0)\n",
    "        \n",
    "        y_pred = (model.predict(X_v) > 0.5).astype(\"int32\")\n",
    "        f1 = f1_score(y_v, y_pred, pos_label=1)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50, n_jobs=6)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'Value: {trial.value}')\n",
    "print('Params:')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "# Create the model with the best parameters from Optuna\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train_reshaped.shape[1], 1)))\n",
    "model.add(Conv1D(filters=best_params['filters'], \n",
    "                 kernel_size=best_params['kernel_size'], \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=best_params['pool_size']))\n",
    "model.add(Conv1D(filters=best_params['filters2'], \n",
    "                 kernel_size=best_params['kernel_size2'], \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=best_params['pool_size2']))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=best_params['units'], activation='relu'))\n",
    "model.add(Dropout(rate=best_params['dropout_rate']))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=best_params['optimizer'],\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[f1_score_metric])\n",
    "\n",
    "# Train the model with the entire training data\n",
    "history = model.fit(X_train_reshaped, y_train, \n",
    "                    epochs=best_params['epochs'], \n",
    "                    batch_size=best_params['batch_size'], \n",
    "                    validation_split=0.2)\n",
    "\n",
    "# Save the trained model to a file\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the test data for CNN\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={'f1_score_metric': f1_score_metric})\n",
    "print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_probs = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1'])\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
